{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253686 entries, 0 to 253685\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   Claim ID            253686 non-null  object        \n",
      " 1   Service Date        253686 non-null  datetime64[ns]\n",
      " 2   Recieved Date       253686 non-null  datetime64[ns]\n",
      " 3   Paid Date           253686 non-null  datetime64[ns]\n",
      " 4   Patient ID          253686 non-null  object        \n",
      " 5   Member Age          253686 non-null  object        \n",
      " 6   Gender              253686 non-null  object        \n",
      " 7   Marital Status      241000 non-null  object        \n",
      " 8   Ethnicity           226800 non-null  object        \n",
      " 9   LOB                 253686 non-null  object        \n",
      " 10  Network Status      253686 non-null  object        \n",
      " 11  Claim Category      253685 non-null  object        \n",
      " 12  Claim Subcategory   253685 non-null  object        \n",
      " 13  Claim Line          253686 non-null  object        \n",
      " 14  Place of Service    253686 non-null  object        \n",
      " 15  Provider Type       253671 non-null  object        \n",
      " 16  Provider Specialty  253685 non-null  object        \n",
      " 17  ICD10 Code 1        252750 non-null  float64       \n",
      " 18  ICD10 Code 2        176154 non-null  float64       \n",
      " 19  ICD10 Code 3        127472 non-null  float64       \n",
      " 20  ICD10 Code 4        95637 non-null   float64       \n",
      " 21  ICD10 Code 5        69465 non-null   float64       \n",
      " 22  ICD10 Code 6        56029 non-null   float64       \n",
      " 23  ICD10 Code 7        45262 non-null   float64       \n",
      " 24  ICD10 Code 8        37466 non-null   float64       \n",
      " 25  ICD10 Code 9        31514 non-null   float64       \n",
      " 26  ICD10 Code 10       26932 non-null   float64       \n",
      " 27  Service Type        253686 non-null  object        \n",
      " 28  Service Code        253686 non-null  object        \n",
      " 29  Modifiers           78847 non-null   object        \n",
      " 30  High Cost Claim     203250 non-null  float64       \n",
      "dtypes: datetime64[ns](3), float64(11), object(17)\n",
      "memory usage: 60.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('Dataset/DSU-Dataset.xlsx')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 188552 entries, 2 to 253685\n",
      "Data columns (total 31 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   Claim ID            188552 non-null  object        \n",
      " 1   Service Date        188552 non-null  datetime64[ns]\n",
      " 2   Recieved Date       188552 non-null  datetime64[ns]\n",
      " 3   Paid Date           188552 non-null  datetime64[ns]\n",
      " 4   Patient ID          188552 non-null  object        \n",
      " 5   Member Age          188552 non-null  object        \n",
      " 6   Gender              188552 non-null  object        \n",
      " 7   Marital Status      179185 non-null  object        \n",
      " 8   Ethnicity           168949 non-null  object        \n",
      " 9   LOB                 188552 non-null  object        \n",
      " 10  Network Status      188552 non-null  object        \n",
      " 11  Claim Category      188551 non-null  object        \n",
      " 12  Claim Subcategory   188551 non-null  object        \n",
      " 13  Claim Line          188552 non-null  object        \n",
      " 14  Place of Service    188552 non-null  object        \n",
      " 15  Provider Type       188546 non-null  object        \n",
      " 16  Provider Specialty  188551 non-null  object        \n",
      " 17  ICD10 Code 1        187763 non-null  float64       \n",
      " 18  ICD10 Code 2        127132 non-null  float64       \n",
      " 19  ICD10 Code 3        88773 non-null   float64       \n",
      " 20  ICD10 Code 4        63691 non-null   float64       \n",
      " 21  ICD10 Code 5        43238 non-null   float64       \n",
      " 22  ICD10 Code 6        32965 non-null   float64       \n",
      " 23  ICD10 Code 7        24889 non-null   float64       \n",
      " 24  ICD10 Code 8        19402 non-null   float64       \n",
      " 25  ICD10 Code 9        15099 non-null   float64       \n",
      " 26  ICD10 Code 10       12091 non-null   float64       \n",
      " 27  Service Type        188552 non-null  object        \n",
      " 28  Service Code        188552 non-null  object        \n",
      " 29  Modifiers           62533 non-null   object        \n",
      " 30  High Cost Claim     188552 non-null  float64       \n",
      "dtypes: datetime64[ns](3), float64(11), object(17)\n",
      "memory usage: 46.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# removes instances of null high cost claims\n",
    "data = data[(data['High Cost Claim'] == 0) | (data['High Cost Claim'] == 1)]\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "selected_features = [\n",
    "    \"Service Date\", \"Recieved Date\", \"Paid Date\", \"Member Age\", \"Gender\", \"LOB\", \n",
    "    \"Network Status\", \"Claim Category\", \"Place of Service\", \"Provider Type\", \n",
    "    \"Provider Specialty\", \"ICD10 Code 1\", \"ICD10 Code 2\", \"ICD10 Code 3\", \n",
    "    \"Service Type\", \"Service Code\", \"High Cost Claim\"\n",
    "]\n",
    "df = data[selected_features].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to datetime format\n",
    "df[\"Service Date\"] = pd.to_datetime(df[\"Service Date\"])\n",
    "df[\"Recieved Date\"] = pd.to_datetime(df[\"Recieved Date\"])\n",
    "df[\"Paid Date\"] = pd.to_datetime(df[\"Paid Date\"])\n",
    "\n",
    "# Create new features\n",
    "df[\"Processing Delay\"] = (df[\"Paid Date\"] - df[\"Recieved Date\"]).dt.days\n",
    "df[\"Claim Lag\"] = (df[\"Recieved Date\"] - df[\"Service Date\"]).dt.days\n",
    "\n",
    "# Drop original date columns\n",
    "df.drop([\"Service Date\", \"Recieved Date\", \"Paid Date\"], axis=1, inplace=True)\n",
    "\n",
    "# Handle categorical variables\n",
    "categorical_cols = [\"Gender\", \"LOB\", \"Network Status\", \"Claim Category\", \"Place of Service\", \"Provider Type\", \"Provider Specialty\", \"Service Type\", \"Service Code\", \"Member Age\"]\n",
    "df[categorical_cols] = df[categorical_cols].astype(str).apply(LabelEncoder().fit_transform)\n",
    "\n",
    "# Handle missing values\n",
    "df.fillna(df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "X = df.drop(\"High Cost Claim\", axis=1).values\n",
    "y = df[\"High Cost Claim\"].values  # Binary classification (0 or 1)\n",
    "\n",
    "# Reshape input for LSTM: (samples, time steps, features)\n",
    "X = X.reshape((X.shape[0], 1, X.shape[1]))  # 1 time step for now\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DSU\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0234 - val_accuracy: 1.0000 - val_loss: 1.2765e-06\n",
      "Epoch 2/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1421e-06 - val_accuracy: 1.0000 - val_loss: 2.0318e-07\n",
      "Epoch 3/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1093e-07 - val_accuracy: 1.0000 - val_loss: 2.5063e-08\n",
      "Epoch 4/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2144e-09 - val_accuracy: 1.0000 - val_loss: 3.0067e-09\n",
      "Epoch 5/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3179e-09 - val_accuracy: 1.0000 - val_loss: 7.6395e-10\n",
      "Epoch 6/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9904e-10 - val_accuracy: 1.0000 - val_loss: 3.6229e-10\n",
      "Epoch 7/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.7345e-11 - val_accuracy: 1.0000 - val_loss: 2.3329e-10\n",
      "Epoch 8/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.0303e-11 - val_accuracy: 1.0000 - val_loss: 1.8586e-10\n",
      "Epoch 9/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0962e-11 - val_accuracy: 1.0000 - val_loss: 1.4801e-10\n",
      "Epoch 10/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1436e-11 - val_accuracy: 1.0000 - val_loss: 1.2260e-10\n",
      "Epoch 11/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0850e-11 - val_accuracy: 1.0000 - val_loss: 1.1123e-10\n",
      "Epoch 12/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5124e-11 - val_accuracy: 1.0000 - val_loss: 9.7441e-11\n",
      "Epoch 13/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.0004e-11 - val_accuracy: 1.0000 - val_loss: 8.8078e-11\n",
      "Epoch 14/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5295e-11 - val_accuracy: 1.0000 - val_loss: 8.2348e-11\n",
      "Epoch 15/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9777e-11 - val_accuracy: 1.0000 - val_loss: 7.6809e-11\n",
      "Epoch 16/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1093e-11 - val_accuracy: 1.0000 - val_loss: 7.1544e-11\n",
      "Epoch 17/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.2296e-12 - val_accuracy: 1.0000 - val_loss: 6.8023e-11\n",
      "Epoch 18/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1285e-11 - val_accuracy: 1.0000 - val_loss: 6.4538e-11\n",
      "Epoch 19/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.5395e-12 - val_accuracy: 1.0000 - val_loss: 6.2050e-11\n",
      "Epoch 20/20\n",
      "\u001b[1m4714/4714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.8581e-12 - val_accuracy: 1.0000 - val_loss: 5.8760e-11\n",
      "\u001b[1m1179/1179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 857us/step - accuracy: 1.0000 - loss: 4.6050e-11\n",
      "Test Accuracy: 1.0000\n",
      "\u001b[1m1179/1179\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     37711\n",
      "\n",
      "    accuracy                           1.00     37711\n",
      "   macro avg       1.00      1.00      1.00     37711\n",
      "weighted avg       1.00      1.00      1.00     37711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
